{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84dbc4ee-8d68-4da0-abc4-0396ace65d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b801a0-d769-4676-8916-438478a5e732",
   "metadata": {},
   "source": [
    "This notebook demonstrates how the optimal HFX values (i.e., those that minimize error between DLPNO-CCSD(T) and a HFX-adjusted semilocal functional using that amount of HFX) were found for each structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad52c3c-1081-4681-a523-60486ad04796",
   "metadata": {},
   "source": [
    "# CSD-76-HFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77cf74d-184e-410f-a971-26acc844357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_df = pd.read_csv('../data/cleaned_csd76_sse.csv').set_index('Unnamed: 0')\n",
    "\n",
    "complexes = sse_df.index\n",
    "functionals = sse_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1bd856-0d08-41ae-b8f9-8a655220f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 72/72 [00:04<00:00, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of structures without sufficient points for PBE is 3.\n",
      "The number of structures without sufficient points for SCAN is 5.\n",
      "The number of structures which required extrapolation for PBE is 2.\n",
      "The number of structures which required extrapolation for SCAN is 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#determine the optimal HFX amount\n",
    "\n",
    "csd_76 = pd.read_csv('../data/CSD-76.csv').set_index('name')\n",
    "\n",
    "def correct_hfx(structure, functional):\n",
    "    df = csd_76\n",
    "    reference = df.loc[structure]['dlpno-CCSD_T.vertsse']\n",
    "\n",
    "    sses = []\n",
    "    all_increments = np.arange(0, 101, 5)\n",
    "    sse_ref = sse_df\n",
    "    increments = []\n",
    "    for increment in all_increments:\n",
    "        sse = sse_ref.loc[structure][functional + '_hfx_' + str(increment)]\n",
    "        if not np.isnan(sse):\n",
    "            increments.append(increment)\n",
    "            sses.append(sse)\n",
    "    if len(increments) < 5:\n",
    "        #print('Not enough converged values!')\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    fit = interp1d(increments, sses, kind='linear', fill_value='extrapolate')\n",
    "    sse_intersection = lambda hfx: (fit(hfx) - reference)**2\n",
    "    res = minimize(sse_intersection, 25, method='Nelder-Mead')#, bounds=((0,100),))\n",
    "    if res.success:\n",
    "        min_error = res.fun\n",
    "        result = res.x[0]\n",
    "    else:\n",
    "        print(idx, res)\n",
    "    #try other initial guesses to see if we can improve\n",
    "    for guess in [0, 50, 75, 100]:\n",
    "        res = minimize(sse_intersection, guess, method='Nelder-Mead')#, bounds=((0,100),))\n",
    "        if res.success:\n",
    "            #if we found a better solution (plus some amount to prevent going away from a found zero)\n",
    "            if res.fun < min_error - 0.1 and res.x[0] >=0 and res.x[0] <= 100:\n",
    "                result = res.x[0]\n",
    "                min_error = res.fun\n",
    "        else:\n",
    "            print(idx, res)\n",
    "    extrapolation = False\n",
    "    if result < increments[0] or result > increments[-1]:\n",
    "        extrapolation = True\n",
    "    return result, extrapolation\n",
    "\n",
    "hfx_df = pd.DataFrame(index=complexes, columns=['hfx_pbe', 'hfx_scan'])\n",
    "\n",
    "pbe_extrapolate = 0\n",
    "scan_extrapolate = 0\n",
    "for name in tqdm(complexes):\n",
    "    a, b = correct_hfx(name, 'pbe')\n",
    "    hfx_df['hfx_pbe'][name] = a\n",
    "    if not np.isnan(b):\n",
    "        pbe_extrapolate += b\n",
    "    a, b = correct_hfx(name, 'scan')\n",
    "    hfx_df['hfx_scan'][name] = a\n",
    "    if not np.isnan(b):\n",
    "        scan_extrapolate += b\n",
    "    \n",
    "\n",
    "print(f'The number of structures without sufficient points for PBE is {np.sum([np.isnan(x) for x in hfx_df[\"hfx_pbe\"].to_numpy()])}.')\n",
    "print(f'The number of structures without sufficient points for SCAN is {np.sum([np.isnan(x) for x in hfx_df[\"hfx_scan\"].to_numpy()])}.')\n",
    "\n",
    "print(f'The number of structures which required extrapolation for PBE is {pbe_extrapolate}.')\n",
    "print(f'The number of structures which required extrapolation for SCAN is {scan_extrapolate}.')\n",
    "\n",
    "hfx_df.to_csv('../data/CSD76targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a761a3-1b75-402b-a73a-d523b4cea418",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfx_df\n",
    "old_df = pd.read_csv('../data/CSD76targets.csv').set_index('Unnamed: 0')\n",
    "\n",
    "for idx, row in hfx_df.iterrows():\n",
    "    if not np.isclose(row['hfx_pbe'], old_df.loc[idx]['hfx_pbe'], equal_nan=True):\n",
    "        print(idx, row['hfx_pbe'], old_df.loc[idx]['hfx_pbe'])\n",
    "    if not np.isclose(row['hfx_scan'], old_df.loc[idx]['hfx_scan'], equal_nan=True):\n",
    "        print(idx, row['hfx_scan'], old_df.loc[idx]['hfx_scan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4d341-86f8-456c-a19c-134fa090fee5",
   "metadata": {},
   "source": [
    "# VSS-452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f244fc-22be-42ec-85a8-b07db833e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_df = pd.read_csv('../data/cleaned_vss452_sse.csv').set_index('Unnamed: 0')\n",
    "\n",
    "complexes = sse_df.index\n",
    "functionals = sse_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad929f6-0108-48ac-8e5d-18648c711bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 452/452 [00:28<00:00, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of structures without sufficient points for PBE is 47.\n",
      "The number of structures without sufficient points for SCAN is 61.\n",
      "The number of structures which required extrapolation for PBE is 33.\n",
      "The number of structures which required extrapolation for SCAN is 51.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vss_452 = pd.read_csv('../data/VSS-452.csv')\n",
    "vss_452 = vss_452.set_index(vss_452['name'])\n",
    "\n",
    "def correct_hfx(structure, functional):\n",
    "    df = vss_452\n",
    "    reference = df.loc[structure.split('/')[-1]]['dlpno-CCSD_T.vertsse']\n",
    "\n",
    "    sses = []\n",
    "    all_increments = np.arange(0, 101, 5)\n",
    "    sse_ref = sse_df\n",
    "    increments = []\n",
    "    for increment in all_increments:\n",
    "        sse = sse_ref.loc[structure][functional + '_hfx_' + str(increment)]\n",
    "        if not np.isnan(sse):\n",
    "            increments.append(increment)\n",
    "            sses.append(sse)\n",
    "    if len(increments) < 5:\n",
    "        #print('Not enough converged values!')\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    fit = interp1d(increments, sses, kind='linear', fill_value='extrapolate')\n",
    "    sse_intersection = lambda hfx: (fit(hfx) - reference)**2\n",
    "    res = minimize(sse_intersection, 25, method='Nelder-Mead')#, bounds=((0,100),))\n",
    "    if res.success:\n",
    "        min_error = res.fun\n",
    "        result = res.x[0]\n",
    "    else:\n",
    "        print(idx, res)\n",
    "    #try other initial guesses to see if we can improve\n",
    "    for guess in [0, 50, 75, 100]:\n",
    "        res = minimize(sse_intersection, guess, method='Nelder-Mead')#, bounds=((0,100),))\n",
    "        if res.success:\n",
    "            #if we found a better solution (plus some amount to prevent going away from a found zero)\n",
    "            if res.fun < min_error - 0.1 and res.x[0] >=0 and res.x[0] <= 100:\n",
    "                result = res.x[0]\n",
    "                min_error = res.fun\n",
    "        else:\n",
    "            print(idx, res)\n",
    "    extrapolation = False\n",
    "    if result < increments[0] or result > increments[-1]:\n",
    "        extrapolation = True\n",
    "    return result, extrapolation\n",
    "\n",
    "hfx_df = pd.DataFrame(index=complexes, columns=['hfx_pbe', 'hfx_scan'])\n",
    "\n",
    "pbe_extrapolate = 0\n",
    "scan_extrapolate = 0\n",
    "for name in tqdm(complexes):\n",
    "    a, b = correct_hfx(name, 'pbe')\n",
    "    hfx_df['hfx_pbe'][name] = a\n",
    "    if not np.isnan(b):\n",
    "        pbe_extrapolate += b\n",
    "    a, b = correct_hfx(name, 'scan')\n",
    "    hfx_df['hfx_scan'][name] = a\n",
    "    if not np.isnan(b):\n",
    "        scan_extrapolate += b\n",
    "    \n",
    "\n",
    "print(f'The number of structures without sufficient points for PBE is {np.sum([np.isnan(x) for x in hfx_df[\"hfx_pbe\"].to_numpy()])}.')\n",
    "print(f'The number of structures without sufficient points for SCAN is {np.sum([np.isnan(x) for x in hfx_df[\"hfx_scan\"].to_numpy()])}.')\n",
    "\n",
    "print(f'The number of structures which required extrapolation for PBE is {pbe_extrapolate}.')\n",
    "print(f'The number of structures which required extrapolation for SCAN is {scan_extrapolate}.')\n",
    "\n",
    "hfx_df.to_csv('../data/VSS452targets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
