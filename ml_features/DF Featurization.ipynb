{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23884a7d-2559-4fe5-9047-fd2cf33d5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6b9c8-4c26-4e9c-9b0c-9655f2cbdf26",
   "metadata": {},
   "source": [
    "This notebook generates the density-fitted features for the structures in VSS-452 and CSD-76. Note that in order to generate these features, you need a Psi4 wave function file for both the high spin and low spin states, and then the features are generated by postprocessing of a density fitting calculation on these, an example of which can be seen in the `density_fitting` subdirectory. Due to the large size of the wave function files, they are not provided in this repository. However, the `density_fitting` subdirectory and this notebook demonstrate how to convert a Psi4 spin-splitting calculation into the features used in this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87535a59-866f-4d4c-bbc1-af20ce8d3b26",
   "metadata": {},
   "source": [
    "# VSS-452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2537c3-a3c2-4a8f-9feb-a073f33b608f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 32, 53, 323, 323)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional = 'scan'\n",
    "\n",
    "path = '../../vss_data/wfns/'+functional+'0/vss452/'\n",
    "\n",
    "folders = [x for x in os.listdir(path) if '.' not in x]\n",
    "output_df = pd.DataFrame(index=folders, columns=['features'])\n",
    "all_data = {'symbol': [], 'spec': []}\n",
    "failed = 0\n",
    "\n",
    "removed = 0\n",
    "energies = pd.read_csv('../data/cleaned_vss452_sse.csv')\n",
    "energies['Unnamed: 0'] = energies['Unnamed: 0'].apply(lambda x: x.split('/')[-1])\n",
    "energies = energies.set_index('Unnamed: 0')\n",
    "\n",
    "for folder in folders:\n",
    "    if np.isnan(energies[functional+'_hfx_25'][folder]):\n",
    "        removed += 1\n",
    "        output_df = output_df.drop([folder])\n",
    "    else:\n",
    "        try:\n",
    "            data = np.load(path + folder + '/df_output.pkl', allow_pickle=True)\n",
    "            all_data['symbol'].append(data['symbol'])\n",
    "            all_data['spec'].append(data['spec'])\n",
    "        except:\n",
    "            failed += 1\n",
    "            output_df = output_df.drop([folder])\n",
    "\n",
    "len(folders), failed, removed, len(output_df), len(all_data['symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a927868-669b-40e4-b5c9-de1df44817d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 65, 117)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_over_all(x: list, padding_len: int = 1) -> dict:\n",
    "    '''\n",
    "    Atom-type-based standardization.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "        x: list,\n",
    "            a list of density fitting features for a specific atom type\n",
    "        padding_len: int, default as 1,\n",
    "            the number of extra padding length; default as 1 for the atom type\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        mean_std: dict,\n",
    "            a dictionary for the mean and std. dev. for the density fitting features\n",
    "    '''\n",
    "    _mean = np.concatenate([np.mean(np.array(x), axis=0), np.array([0 for _ in range(padding_len)])], axis=-1)\n",
    "    _std = np.std(np.array(x), axis=0)\n",
    "    _std[_std < 1e-6] = 1\n",
    "    _std = np.concatenate([_std, np.array([1 for _ in range(padding_len)])], axis=-1)\n",
    "    mean_std = {\"mean\": _mean, \"std\": _std} \n",
    "    return mean_std\n",
    "    \n",
    "atoms  = [\"X\", \"H\", \"C\", \"N\", \"O\", \"F\", \"Cr\", \"Mn\", \"Fe\", \"Co\"] # X represent a \"vacuum\" atom\n",
    "atom_maps = {\"X\": 0, \"H\": 1, \"C\": 2, \"N\": 3, \"O\": 4, \"F\": 5, \"P\": 3, \"S\": 4, \"Cl\": 5, \"Cr\": 6, \"Mn\": 7, \"Fe\": 8, \"Co\": 9}\n",
    "ele_group = {\"H\": \"H\", \"C\": \"C\", \"N\": \"N\", \"O\": \"O\", \"F\": \"F\", \"P\": \"N\", \"S\": \"O\", \"Cl\": \"F\", \n",
    "             \"Cr\": \"Cr\", \"Mn\": \"Mn\", \"Fe\": \"Fe\", \"Co\": \"Co\"} # here we use the same local network for 2p/3p pairs.\n",
    "max_size = 65 # largest number of atoms in the complexes of VSS-452. But the models is not limited by the size of atoms after trained.\n",
    "\n",
    "res_tot = all_data\n",
    "tot_sample = len(res_tot[\"symbol\"])\n",
    "\n",
    "# ---normalize density fitting features---\n",
    "standard_dict, arrs = {}, {}\n",
    "for ele in atoms[1:]:\n",
    "    arrs[ele] = []\n",
    "    standard_dict[ele] = {}\n",
    "for ii in range(tot_sample):\n",
    "    for jj, ele in enumerate(res_tot[\"symbol\"][ii]):\n",
    "        _den_alpha = np.pad(np.array(res_tot[\"spec\"][ii]['alpha'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])))\n",
    "        _den_beta = np.pad(np.array(res_tot[\"spec\"][ii]['beta'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])))\n",
    "        _tot = np.concatenate([_den_alpha, _den_beta], axis=-1)\n",
    "        arrs[ele_group[ele]] += [_tot]\n",
    "for ele in atoms[1:]:\n",
    "    standard_dict[ele]  = standardize_over_all(arrs[ele], padding_len=1)\n",
    "standard_dict[\"X\"] = {\"mean\": np.zeros(shape=(58*2 + 1, )), \"std\": np.ones(shape=(58*2 + 1, ))}\n",
    "\n",
    "# ---get normalized features---\n",
    "X = np.zeros(shape=(tot_sample, max_size, 58*2 + 1))\n",
    "c = 0\n",
    "for ii in range(tot_sample):\n",
    "    for jj, ele in enumerate(res_tot['symbol'][ii]):\n",
    "        _den_alpha = np.pad(np.array(res_tot[\"spec\"][ii]['alpha'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])), 'constant', constant_values=(0, 0))\n",
    "        _den_beta = np.pad(np.array(res_tot[\"spec\"][ii]['beta'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])), 'constant', constant_values=(0, 0))\n",
    "        _tot = np.concatenate([_den_alpha, _den_beta, np.array([atom_maps[ele]])], axis=-1)\n",
    "        X[c, jj, :] = (_tot - standard_dict[ele_group[ele]][\"mean\"])/standard_dict[ele_group[ele]][\"std\"]\n",
    "    c += 1\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93050d22-5119-4358-b28b-661cb9e2d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "with open(\"BP_features/\"+functional+\"0-vss452_X.pkl\", \"wb\") as fo:\n",
    "    pickle.dump(X, fo)\n",
    "\n",
    "with open(\"BP_features/\"+functional+\"0-standard_dict.pkl\", \"wb\") as fo:\n",
    "    pickle.dump(standard_dict, fo)\n",
    "\n",
    "output_df.to_csv(\"BP_features/\"+functional+\"0-vss452_structures.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96459d18-48ab-4433-97bc-2d9185867647",
   "metadata": {},
   "source": [
    "# CSD-76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19da52ae-2fac-4b07-8687-dd32fbb6a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 1, 3, 64, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../vss_data/wfns/'+functional+'0/csd76/'\n",
    "\n",
    "folders = [x for x in os.listdir(path) if '.' not in x and 'Cr' not in x]\n",
    "output_df = pd.DataFrame(index=folders, columns=['features'])\n",
    "all_data = {'symbol': [], 'spec': []}\n",
    "failed = 0\n",
    "\n",
    "removed = 0\n",
    "energies = pd.read_csv('../data/cleaned_csd76_sse.csv')\n",
    "energies = energies.set_index('Unnamed: 0')\n",
    "\n",
    "for folder in folders:\n",
    "    if np.isnan(energies[functional+'_hfx_25'][folder]):\n",
    "        removed += 1\n",
    "        output_df = output_df.drop([folder])\n",
    "    else:\n",
    "        try:\n",
    "            data = np.load(path + folder + '/df_output.pkl', allow_pickle=True)\n",
    "            all_data['symbol'].append(data['symbol'])\n",
    "            all_data['spec'].append(data['spec'])\n",
    "        except:\n",
    "            failed += 1\n",
    "            output_df = output_df.drop([folder])\n",
    "\n",
    "len(folders), failed, removed, len(output_df), len(all_data['symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a426a5c-3097-4451-8f63-dc50acc74b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 65, 117)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_dict = np.load(\"BP_features/\"+functional+\"0-standard_dict.pkl\", allow_pickle=True)\n",
    "    \n",
    "atoms  = [\"X\", \"H\", \"C\", \"N\", \"O\", \"F\", \"Cr\", \"Mn\", \"Fe\", \"Co\"] # X represent a \"vacuum\" atom\n",
    "atom_maps = {\"X\": 0, \"H\": 1, \"C\": 2, \"N\": 3, \"O\": 4, \"F\": 5, \"P\": 3, \"S\": 4, \"Cl\": 5, \"Cr\": 6, \"Mn\": 7, \"Fe\": 8, \"Co\": 9}\n",
    "ele_group = {\"H\": \"H\", \"C\": \"C\", \"N\": \"N\", \"O\": \"O\", \"F\": \"F\", \"P\": \"N\", \"S\": \"O\", \"Cl\": \"F\", \n",
    "             \"Cr\": \"Cr\", \"Mn\": \"Mn\", \"Fe\": \"Fe\", \"Co\": \"Co\"} # here we use the same local network for 2p/3p pairs.\n",
    "max_size = 65 # largest number of atoms in the complexes of VSS-452. But the models is not limited by the size of atoms after trained.\n",
    "\n",
    "res_tot = all_data\n",
    "tot_sample = len(res_tot[\"symbol\"])\n",
    "\n",
    "# ---get normalized features---\n",
    "X = np.zeros(shape=(tot_sample, max_size, 58*2 + 1))\n",
    "c = 0\n",
    "for ii in range(tot_sample):\n",
    "    for jj, ele in enumerate(res_tot['symbol'][ii]):\n",
    "        _den_alpha = np.pad(np.array(res_tot[\"spec\"][ii]['alpha'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])), 'constant', constant_values=(0, 0))\n",
    "        _den_beta = np.pad(np.array(res_tot[\"spec\"][ii]['beta'][jj]), (0, 58-len(res_tot[\"spec\"][ii]['alpha'][jj])), 'constant', constant_values=(0, 0))\n",
    "        _tot = np.concatenate([_den_alpha, _den_beta, np.array([atom_maps[ele]])], axis=-1)\n",
    "        X[c, jj, :] = (_tot - standard_dict[ele_group[ele]][\"mean\"])/standard_dict[ele_group[ele]][\"std\"]\n",
    "    c += 1\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68be471d-71e8-42b3-b269-37f998f0ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "with open(\"BP_features/\"+functional+\"0-csd76_X.pkl\", \"wb\") as fo:\n",
    "    pickle.dump(X, fo)\n",
    "\n",
    "output_df.to_csv(\"BP_features/\"+functional+\"0-csd76_structures.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
